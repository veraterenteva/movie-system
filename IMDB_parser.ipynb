{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Парсинг данных\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "На парсинг 5000 фильмов уходит ~20 минут. Данные не всегда причёсаны, как, например, с годом выхода, это обрабатывается в следующих лабах (хотя конкретно в этом вопросе обычно берётся год начала производства)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifwxsWIiAZLH"
      },
      "outputs": [],
      "source": [
        "from requests import get\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "from time import sleep\n",
        "from random import randint\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "import re\n",
        "\n",
        "import json\n",
        "\n",
        "import asyncio\n",
        "import aiohttp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PsEEV9308oo"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kd_z_iGL15Zd"
      },
      "outputs": [],
      "source": [
        "pd.options.display.max_columns = None\n",
        "pd.options.display.max_rows = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF7-Yjl02Cf_",
        "outputId": "2b43f92c-6516-40fb-bb8a-4c3526411b82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px4YI-NW2NNp",
        "outputId": "519953d0-e417-440b-e51e-d24587b059d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/Lab1’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir '/content/drive/MyDrive/Lab1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "UV67MdfFVzFO",
        "outputId": "2778a0c8-83b8-4d5c-97b6-02567738b594"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-86c09ac3e58f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'config.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'config.json'"
          ]
        }
      ],
      "source": [
        "with open('config.json', 'r') as f:\n",
        "    params = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-5GAVHN2ZSY"
      },
      "outputs": [],
      "source": [
        "path_data = '/content/drive/MyDrive/Lab1/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HF1nedo15nqC"
      },
      "outputs": [],
      "source": [
        "params = {'url' : \"https://www.imdb.com/search/title/?genres=drama\",\n",
        "    \"movies_to_parse\": \"50000\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-A79KPSu8gWn"
      },
      "outputs": [],
      "source": [
        "class Crawler:\n",
        "  def __init__(self, movies_to_parse, path_url):\n",
        "      self.movies_to_parse = movies_to_parse\n",
        "      self.path_url = path_url\n",
        "      self.columns = ['title', 'genre', 'year', 'certificate', 'runtime', 'user-votes', 'imdb-scores', 'metacritic-scores', 'descriptions', 'stars']\n",
        "\n",
        "      self.all_titles = pd.Series()\n",
        "      self.all_years = pd.Series()\n",
        "      self.all_genres = pd.Series()\n",
        "      self.all_certificates = pd.Series()\n",
        "      self.all_runtimes = pd.Series()\n",
        "      self.all_votes = pd.Series()\n",
        "      self.all_imdb_scores = pd.Series()\n",
        "      self.all_metacritic_scores = pd.Series()\n",
        "      self.all_descriptions = pd.Series()\n",
        "      self.all_stars = pd.Series()\n",
        "\n",
        "  def get_dataset(self):\n",
        "      self.iterate_over_pages()\n",
        "\n",
        "      data_titles = pd.DataFrame(self.all_titles, columns=['title'])\n",
        "      data_genres = pd.DataFrame(self.all_genres, columns=['genre'])\n",
        "      data_years = pd.DataFrame(self.all_years, columns=['year'])\n",
        "      data_certificates = pd.DataFrame(self.all_certificates, columns=['certificate'])\n",
        "      data_runtimes = pd.DataFrame(self.all_runtimes, columns=['runtime'])\n",
        "      data_votes = pd.DataFrame(self.all_votes, columns=['user-votes'])\n",
        "      data_imdb_scores = pd.DataFrame(self.all_imdb_scores, columns=['imdb-scores'])\n",
        "      data_metacritic_scores = pd.DataFrame(self.all_metacritic_scores, columns=['metacritic-scores'])\n",
        "      data_descriptions = pd.DataFrame(self.all_descriptions, columns=['descriptions'])\n",
        "      data_stars = pd.DataFrame(self.all_stars, columns=['stars'])\n",
        "\n",
        "      data = pd.concat([data_titles, data_genres, data_years, data_certificates, data_runtimes, data_votes, data_imdb_scores, data_metacritic_scores, data_descriptions,\n",
        "                        data_stars], axis=1, ignore_index = True)\n",
        "      data.columns = self.columns\n",
        "\n",
        "      return data\n",
        "\n",
        "  def iterate_over_pages(self):\n",
        "      for i in tqdm(range(1, self.movies_to_parse, 50)):\n",
        "          url = self.path_url + \"&start=\" + str(i) + \"&ref_=adv_nxt\"\n",
        "          current_soup = self.get_bs(url)\n",
        "          parser = Parser(current_soup)\n",
        "\n",
        "          self.get_titles(parser)\n",
        "          self.get_years(parser)\n",
        "          self.get_genres(parser)\n",
        "          self.get_age_rating(parser)\n",
        "          self.get_runtimes(parser)\n",
        "          self.get_imdb_scores(parser)\n",
        "          self.get_metacritic_scores(parser)\n",
        "          self.get_votes(parser)\n",
        "          self.get_descriptions(parser)\n",
        "          self.get_stars(parser)\n",
        "\n",
        "\n",
        "  def get_bs(self, url):\n",
        "      response = requests.get(url=url)\n",
        "      soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "      return soup\n",
        "\n",
        "  def get_titles(self, parser):\n",
        "      page_titles = Parser.unique_movie_title(parser)\n",
        "      self.all_titles = pd.concat([self.all_titles, page_titles], ignore_index = True)\n",
        "\n",
        "  def get_genres(self, parser):\n",
        "      page_genres = Parser.unique_movie_genre(parser)\n",
        "      self.all_genres = pd.concat([self.all_genres, page_genres], ignore_index = True)\n",
        "\n",
        "  def get_years(self, parser):\n",
        "      page_years = Parser.unique_movie_year(parser)\n",
        "      self.all_years = pd.concat([self.all_years, page_years], ignore_index = True)\n",
        "\n",
        "  def get_age_rating(self, parser):\n",
        "      page_certificate = Parser.unique_movie_age_rating(parser)\n",
        "      self.all_certificates = pd.concat([self.all_certificates, page_certificate], ignore_index = True)\n",
        "\n",
        "  def get_runtimes(self, parser):\n",
        "      page_runtimes = Parser.unique_movie_runtime(parser)\n",
        "      self.all_runtimes = pd.concat([self.all_runtimes, page_runtimes], ignore_index = True)\n",
        "\n",
        "  def get_imdb_scores(self, parser):\n",
        "      page_scores = Parser.unique_movie_imdb_score(parser)\n",
        "      self.all_imdb_scores = pd.concat([self.all_imdb_scores, page_scores], ignore_index = True)\n",
        "\n",
        "  def get_votes(self, parser):\n",
        "      page_votes = Parser.unique_movie_vote(parser)\n",
        "      self.all_votes = pd.concat([self.all_votes, page_votes], ignore_index = True)\n",
        "\n",
        "  def get_metacritic_scores(self, parser):\n",
        "      page_metacritic_scores = Parser.unique_movie_metacritic_score(parser)\n",
        "      self.all_metacritic_scores = pd.concat([self.all_metacritic_scores, page_metacritic_scores], ignore_index = True)\n",
        "\n",
        "  def get_descriptions(self, parser):\n",
        "      page_descriptions = Parser.unique_movie_description(parser)\n",
        "      self.all_descriptions = pd.concat([self.all_descriptions, page_descriptions], ignore_index = True)\n",
        "\n",
        "  def get_stars(self, parser):\n",
        "      page_stars = Parser.unique_stars(parser)\n",
        "      self.all_stars = pd.concat([self.all_stars, page_stars], ignore_index = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxZPAoBDA_Ad"
      },
      "outputs": [],
      "source": [
        "class Parser:\n",
        "  def __init__(self, soup):\n",
        "      self.soup = soup\n",
        "\n",
        "  # 1. Название\n",
        "  def unique_movie_title(self):\n",
        "      unique_strings_title = set()\n",
        "\n",
        "      div_tags = self.soup.find_all(\"div\", class_=\"lister-item-content\")\n",
        "      unique_strings_title = [div_tag.find(\"h3\", class_=\"lister-item-header\").find(\"a\").text for div_tag in div_tags]\n",
        "\n",
        "      titles = pd.Series(unique_strings_title)\n",
        "      return titles\n",
        "\n",
        "  # 2. Год производства\n",
        "  def unique_movie_year(self):\n",
        "      unique_strings_year = set()\n",
        "\n",
        "      div_tags = self.soup.find_all(\"div\", class_=\"lister-item-content\")\n",
        "      unique_strings_year = [div_tag.find(\"h3\", class_=\"lister-item-header\").find(\"span\", class_=\"lister-item-year text-muted unbold\").text for div_tag in div_tags]\n",
        "\n",
        "      cleaned_data = []\n",
        "      for year in unique_strings_year:\n",
        "        cleaned_item = re.sub(r'[^0-9]+', '', year)\n",
        "        if '-' in cleaned_item:\n",
        "            cleaned_item = cleaned_item.split('-')[0]\n",
        "        cleaned_data.append(cleaned_item)\n",
        "\n",
        "      years = pd.Series(cleaned_data)\n",
        "      return years\n",
        "\n",
        "  # 3. Жанр\n",
        "  def unique_movie_genre(self):\n",
        "      unique_strings_movie_genre = set()\n",
        "\n",
        "      div_tags = self.soup.find_all(\"div\", class_=\"lister-item-content\")\n",
        "      unique_strings_movie_genre = [div_tag.find(\"p\", class_=\"text-muted\").find(\"span\", class_ = \"genre\").text for div_tag in div_tags]\n",
        "      genres = [genre.replace(' ', '').strip() for genre in unique_strings_movie_genre]\n",
        "\n",
        "      genres = pd.Series(genres)\n",
        "      return genres\n",
        "\n",
        "  # 4. Возрастной ценз\n",
        "  def unique_movie_age_rating(self):\n",
        "      unique_strings_movie_age_rating = []\n",
        "\n",
        "      div_tags = self.soup.find_all(\"div\", class_=\"lister-item-content\")\n",
        "\n",
        "      for div_tag in div_tags:\n",
        "        try:\n",
        "          certificate = div_tag.find(\"p\", class_=\"text-muted\").find(\"span\", class_ = \"certificate\").text\n",
        "        except:\n",
        "          certificate = \"No data\"\n",
        "        unique_strings_movie_age_rating.append(certificate)\n",
        "\n",
        "      ratings = pd.Series(unique_strings_movie_age_rating)\n",
        "\n",
        "      return ratings\n",
        "\n",
        "\n",
        "  # 5. Продолжительность\n",
        "  def unique_movie_runtime(self):\n",
        "      unique_strings_movie_runtime = []\n",
        "\n",
        "      div_tags = self.soup.find_all(\"div\", class_=\"lister-item-content\")\n",
        "\n",
        "      for div_tag in div_tags:\n",
        "        try:\n",
        "          certificate = div_tag.find(\"p\", class_=\"text-muted\").find(\"span\", class_=\"runtime\")\n",
        "          certificate = certificate.text.removesuffix(\" min\")\n",
        "        except:\n",
        "          certificate = \"No data\"\n",
        "        unique_strings_movie_runtime.append(certificate)\n",
        "\n",
        "      runtime = pd.Series(unique_strings_movie_runtime)\n",
        "\n",
        "      return runtime\n",
        "\n",
        "  # 6. Рейтинг imdb\n",
        "  def unique_movie_imdb_score(self):\n",
        "      unique_movie_imdb_score = []\n",
        "\n",
        "      div_tags = self.soup.find_all(\"div\", class_=\"lister-item-content\")\n",
        "\n",
        "      for div_tag in div_tags:\n",
        "        try:\n",
        "          score = div_tag.find(\"div\", class_=\"ratings-bar\").find(\"div\", class_=\"inline-block ratings-imdb-rating\")\n",
        "          score = score.text\n",
        "        except:\n",
        "          score = \"No data\"\n",
        "        unique_movie_imdb_score.append(score)\n",
        "\n",
        "      scores = [score.strip() for score in unique_movie_imdb_score]\n",
        "      scores = pd.Series(scores)\n",
        "\n",
        "      return scores\n",
        "\n",
        "  # 7. Количество голосов\n",
        "  def unique_movie_vote(self):\n",
        "      unique_movie_vote = []\n",
        "\n",
        "      div_tags = self.soup.find_all(\"div\", class_=\"lister-item-content\")\n",
        "\n",
        "      for div_tag in div_tags:\n",
        "        try:\n",
        "          vote = div_tag.find(\"p\", class_=\"sort-num_votes-visible\")\n",
        "          vote = (re.findall(r'[0-9]+', str(vote)))[0]\n",
        "        except:\n",
        "          vote = \"No data\"\n",
        "        unique_movie_vote.append(vote)\n",
        "\n",
        "      votes = pd.Series(unique_movie_vote)\n",
        "      return votes\n",
        "\n",
        "\n",
        "  # 8. Рейтинг Metacritic\n",
        "  def unique_movie_metacritic_score(self):\n",
        "      unique_movie_metacritic_score = []\n",
        "\n",
        "      div_tags = self.soup.find_all(\"div\", class_=\"lister-item-content\")\n",
        "\n",
        "      for div_tag in div_tags:\n",
        "        try:\n",
        "          score = div_tag.find(\"div\", class_=\"ratings-bar\")\n",
        "          score = score.find(\"div\", class_=\"inline-block ratings-metascore\").text\n",
        "          unique_movie_metacritic_score.append(re.findall(r'\\d+', score)[0])\n",
        "        except:\n",
        "          unique_movie_metacritic_score.append(\"No data\")\n",
        "\n",
        "      scores = pd.Series(unique_movie_metacritic_score)\n",
        "      return scores\n",
        "\n",
        "\n",
        "  # 9. Описания режиссёры, актёры\n",
        "  def unique_movie_description(self):\n",
        "      unique_strings_movie_description = []\n",
        "\n",
        "      for div_tags in self.soup.select(\"div.lister-item-content > p.text-muted:nth-of-type(2)\"):\n",
        "          try:\n",
        "            descriptions = div_tags.text.strip('\\n')\n",
        "          except:\n",
        "            descriptions = None\n",
        "\n",
        "          unique_strings_movie_description.append(descriptions)\n",
        "\n",
        "      descriptions = pd.Series(unique_strings_movie_description)\n",
        "\n",
        "      return descriptions\n",
        "\n",
        "  #10. Звёзды\n",
        "  def unique_stars(self):\n",
        "      unique_stars = []\n",
        "\n",
        "      for div_tags in self.soup.select(\"div.lister-item-content > p:nth-of-type(3)\"):\n",
        "        try:\n",
        "          unique_star = div_tags.text.strip('\\n')\n",
        "        except:\n",
        "          unique_star = None\n",
        "        unique_stars.append(unique_star)\n",
        "      stars = pd.Series(unique_stars)\n",
        "\n",
        "      return stars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X77qG5ADBXzE",
        "outputId": "cdc4a09d-48dc-4ff4-af4d-07e79a129499"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [19:57<00:00,  1.20s/it]\n"
          ]
        }
      ],
      "source": [
        "crawl = Crawler(int(params[\"movies_to_parse\"]), params[\"url\"])\n",
        "df_movies = Crawler.get_dataset(crawl)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQWanXlXYy2n"
      },
      "outputs": [],
      "source": [
        "df_movies.to_csv('drive/MyDrive/Lab1/movies_50000.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
